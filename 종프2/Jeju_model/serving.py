"""
ì €ì¥ëœ ëª¨ë¸ì„ ë¡œë“œí•˜ì—¬ ìƒˆë¡œìš´ ë°ì´í„°ì— ëŒ€í•´ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ëŠ” ì˜ˆì œ
"""

import torch
import torch.nn as nn
import numpy as np
import pandas as pd
import pickle
import json
import os
import xgboost as xgb

# GPU/CUDA ì„¤ì •
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ğŸš€ ì‚¬ìš© ì¤‘ì¸ ë””ë°”ì´ìŠ¤: {device}")


# === ëª¨ë¸ í´ë˜ìŠ¤ ì •ì˜ (í•™ìŠµ ì½”ë“œì™€ ë™ì¼) ===
class LSTMModel(nn.Module):
    def __init__(self, input_size, hidden_size=128, num_layers=2, dropout=0.2):
        super(LSTMModel, self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        
        self.lstm = nn.LSTM(
            input_size, 
            hidden_size, 
            num_layers, 
            batch_first=True,
            dropout=dropout if num_layers > 1 else 0
        )
        self.fc = nn.Linear(hidden_size, 1)
        self.dropout = nn.Dropout(dropout)
    
    def forward(self, x):
        lstm_out, _ = self.lstm(x)
        lstm_out = self.dropout(lstm_out[:, -1, :])
        output = self.fc(lstm_out)
        return output


class GRUModel(nn.Module):
    def __init__(self, input_size, hidden_size=128, num_layers=2, dropout=0.2):
        super(GRUModel, self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        
        self.gru = nn.GRU(
            input_size, 
            hidden_size, 
            num_layers, 
            batch_first=True,
            dropout=dropout if num_layers > 1 else 0
        )
        self.fc = nn.Linear(hidden_size, 1)
        self.dropout = nn.Dropout(dropout)
    
    def forward(self, x):
        gru_out, _ = self.gru(x)
        gru_out = self.dropout(gru_out[:, -1, :])
        output = self.fc(gru_out)
        return output


# === ëª¨ë¸ ë¡œë“œ í•¨ìˆ˜ ===
def load_trained_models(model_dir='./saved_models', timestamp=None):
    """
    ì €ì¥ëœ ëª¨ë¸ê³¼ ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
    
    Args:
        model_dir: ëª¨ë¸ì´ ì €ì¥ëœ ë””ë ‰í† ë¦¬
        timestamp: íŠ¹ì • ì‹œì ì˜ ëª¨ë¸ì„ ë¡œë“œí•˜ë ¤ë©´ íƒ€ì„ìŠ¤íƒ¬í”„ ì§€ì •
                  Noneì´ë©´ ìµœì‹  ëª¨ë¸ ë¡œë“œ
    
    Returns:
        dict: ë¡œë“œëœ ëª¨ë¸, ìŠ¤ì¼€ì¼ëŸ¬, ë©”íƒ€ë°ì´í„°ë¥¼ í¬í•¨í•˜ëŠ” ë”•ì…”ë„ˆë¦¬
    """
    print(f"\n{'='*80}")
    print("ëª¨ë¸ ë¡œë“œ ì¤‘...")
    print(f"{'='*80}")
    
    # ìµœì‹  ëª¨ë¸ ì •ë³´ ë¡œë“œ
    if timestamp is None:
        latest_path = os.path.join(model_dir, 'latest_models.json')
        if not os.path.exists(latest_path):
            raise FileNotFoundError(f"ìµœì‹  ëª¨ë¸ ì •ë³´ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {latest_path}")
        
        with open(latest_path, 'r', encoding='utf-8') as f:
            model_info = json.load(f)
        
        timestamp = model_info['timestamp']
        print(f"âœ… ìµœì‹  ëª¨ë¸ íƒ€ì„ìŠ¤íƒ¬í”„: {timestamp}")
    
    # ë©”íƒ€ë°ì´í„° ë¡œë“œ
    metadata_path = os.path.join(model_dir, f'metadata_{timestamp}.json')
    with open(metadata_path, 'r', encoding='utf-8') as f:
        metadata = json.load(f)
    
    print(f"âœ… ë©”íƒ€ë°ì´í„° ë¡œë“œ: {metadata_path}")
    
    # ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
    scaler_path = os.path.join(model_dir, f'scalers_{timestamp}.pkl')
    with open(scaler_path, 'rb') as f:
        scalers = pickle.load(f)
    
    scaler_X = scalers['scaler_X']
    scaler_y = scalers['scaler_y']
    print(f"âœ… ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ: {scaler_path}")
    
    # LSTM ëª¨ë¸ ë¡œë“œ
    lstm_path = os.path.join(model_dir, f'lstm_model_{timestamp}.pth')
    lstm_checkpoint = torch.load(lstm_path, map_location=device)
    lstm_config = lstm_checkpoint['model_config']
    
    lstm_model = LSTMModel(
        input_size=lstm_config['input_size'],
        hidden_size=lstm_config['hidden_size'],
        num_layers=lstm_config['num_layers']
    ).to(device)
    lstm_model.load_state_dict(lstm_checkpoint['model_state_dict'])
    lstm_model.eval()
    print(f"âœ… LSTM ëª¨ë¸ ë¡œë“œ: {lstm_path}")
    print(f"   - Input size: {lstm_config['input_size']}")
    print(f"   - Hidden size: {lstm_config['hidden_size']}")
    print(f"   - Num layers: {lstm_config['num_layers']}")
    
    # GRU ëª¨ë¸ ë¡œë“œ
    gru_path = os.path.join(model_dir, f'gru_model_{timestamp}.pth')
    gru_checkpoint = torch.load(gru_path, map_location=device)
    gru_config = gru_checkpoint['model_config']
    
    gru_model = GRUModel(
        input_size=gru_config['input_size'],
        hidden_size=gru_config['hidden_size'],
        num_layers=gru_config['num_layers']
    ).to(device)
    gru_model.load_state_dict(gru_checkpoint['model_state_dict'])
    gru_model.eval()
    print(f"âœ… GRU ëª¨ë¸ ë¡œë“œ: {gru_path}")
    print(f"   - Input size: {gru_config['input_size']}")
    print(f"   - Hidden size: {gru_config['hidden_size']}")
    print(f"   - Num layers: {gru_config['num_layers']}")
    
    # XGBoost ëª¨ë¸ ë¡œë“œ
    xgb_path = os.path.join(model_dir, f'xgboost_stacking_{timestamp}.json')
    xgb_model = xgb.XGBRegressor()
    xgb_model.load_model(xgb_path)
    print(f"âœ… XGBoost ìŠ¤íƒœí‚¹ ëª¨ë¸ ë¡œë“œ: {xgb_path}")
    
    # ëª¨ë¸ ì„±ëŠ¥ ì •ë³´ ì¶œë ¥
    print(f"\n{'='*80}")
    print("ëª¨ë¸ ì„±ëŠ¥ ì •ë³´")
    print(f"{'='*80}")
    print("\nLSTM ëª¨ë¸:")
    for metric, value in lstm_checkpoint.get('metrics', {}).items():
        print(f"  {metric}: {value:.4f}" if isinstance(value, (int, float)) else f"  {metric}: {value}")
    
    print("\nGRU ëª¨ë¸:")
    for metric, value in gru_checkpoint.get('metrics', {}).items():
        print(f"  {metric}: {value:.4f}" if isinstance(value, (int, float)) else f"  {metric}: {value}")
    
    print("\nXGBoost ìŠ¤íƒœí‚¹ ëª¨ë¸:")
    for metric, value in metadata.get('stacked_metrics', {}).items():
        print(f"  {metric}: {value:.4f}" if isinstance(value, (int, float)) else f"  {metric}: {value}")
    
    print(f"\n{'='*80}")
    print("âœ¨ ëª¨ë“  ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
    print(f"{'='*80}")
    
    return {
        'lstm_model': lstm_model,
        'gru_model': gru_model,
        'xgb_model': xgb_model,
        'scaler_X': scaler_X,
        'scaler_y': scaler_y,
        'metadata': metadata
    }


# === ì˜ˆì¸¡ í•¨ìˆ˜ ===
def predict_solar_generation(new_data, models_dict, sequence_length=24):
    """
    ìƒˆë¡œìš´ ë°ì´í„°ì— ëŒ€í•´ íƒœì–‘ê´‘ ë°œì „ëŸ‰ ì˜ˆì¸¡
    
    Args:
        new_data: pandas DataFrame ë˜ëŠ” numpy array (íŠ¹ì„± ë°ì´í„°)
                  shape: (n_samples, n_features)
        models_dict: load_trained_models()ì—ì„œ ë°˜í™˜ëœ ë”•ì…”ë„ˆë¦¬
        sequence_length: ì‹œí€€ìŠ¤ ê¸¸ì´ (ê¸°ë³¸ê°’: 24)
    
    Returns:
        dict: LSTM, GRU, ìŠ¤íƒœí‚¹ ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°ê³¼
    """
    # ëª¨ë¸ê³¼ ìŠ¤ì¼€ì¼ëŸ¬ ì¶”ì¶œ
    lstm_model = models_dict['lstm_model']
    gru_model = models_dict['gru_model']
    xgb_model = models_dict['xgb_model']
    scaler_X = models_dict['scaler_X']
    scaler_y = models_dict['scaler_y']
    metadata = models_dict['metadata']
    
    # íŠ¹ì„± ì»¬ëŸ¼ ì •ë³´
    feature_cols = metadata['feature_columns']
    expected_features = len(feature_cols)
    
    print(f"\nì˜ˆì¸¡ ë°ì´í„° ì •ë³´:")
    print(f"  ì˜ˆìƒ íŠ¹ì„± ê°œìˆ˜: {expected_features}")
    print(f"  ì˜ˆìƒ íŠ¹ì„± ëª©ë¡: {feature_cols}")
    
    # ë°ì´í„° í˜•ì‹ ë³€í™˜ ë° íŠ¹ì„± ìˆœì„œ ë³´ì¥
    if isinstance(new_data, pd.DataFrame):
        print(f"  ì…ë ¥ ë°ì´í„° shape: {new_data.shape}")
        print(f"  ì…ë ¥ ë°ì´í„° ì»¬ëŸ¼: {list(new_data.columns)}")
        
        # ë©”íƒ€ë°ì´í„°ì˜ feature ìˆœì„œëŒ€ë¡œ ì •ë ¬
        try:
            new_data = new_data[feature_cols].values
            print(f"  âœ… íŠ¹ì„± ì»¬ëŸ¼ ìˆœì„œ ì •ë ¬ ì™„ë£Œ")
        except KeyError as e:
            missing_cols = set(feature_cols) - set(new_data.columns)
            print(f"  âŒ ì˜¤ë¥˜: ë‹¤ìŒ ì»¬ëŸ¼ì´ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤: {missing_cols}")
            raise ValueError(f"í•„ìˆ˜ íŠ¹ì„± ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing_cols}")
    else:
        print(f"  ì…ë ¥ ë°ì´í„° shape: {new_data.shape}")
        if new_data.shape[1] != expected_features:
            raise ValueError(
                f"ì…ë ¥ ë°ì´í„°ì˜ íŠ¹ì„± ê°œìˆ˜({new_data.shape[1]})ê°€ "
                f"ì˜ˆìƒê³¼ ë‹¤ë¦…ë‹ˆë‹¤(ì˜ˆìƒ: {expected_features})"
            )
    
    # ë°ì´í„°ê°€ ì‹œí€€ìŠ¤ ê¸¸ì´ë³´ë‹¤ ì‘ìœ¼ë©´ ì—ëŸ¬
    if len(new_data) < sequence_length:
        raise ValueError(f"ë°ì´í„° ê¸¸ì´({len(new_data)})ê°€ ì‹œí€€ìŠ¤ ê¸¸ì´({sequence_length})ë³´ë‹¤ ì‘ìŠµë‹ˆë‹¤.")
    
    # ê²°ì¸¡ê°’ ì²˜ë¦¬ - numpy arrayë¡œ ë³€í™˜ í›„ ì²˜ë¦¬
    new_data_imputed = new_data.copy()
    
    print(f"\nê²°ì¸¡ê°’ ì²˜ë¦¬:")
    # ê° ì»¬ëŸ¼ì˜ ê²°ì¸¡ê°’ í™•ì¸ ë° ì²˜ë¦¬
    for col_idx in range(new_data_imputed.shape[1]):
        col_data = new_data_imputed[:, col_idx]
        nan_count = np.sum(np.isnan(col_data))
        
        if nan_count > 0:
            col_name = feature_cols[col_idx] if col_idx < len(feature_cols) else f"ì»¬ëŸ¼ {col_idx}"
            
            if np.all(np.isnan(col_data)):
                # ì™„ì „íˆ ê²°ì¸¡ì¸ ì»¬ëŸ¼ì€ 0ìœ¼ë¡œ ì±„ì›€
                new_data_imputed[:, col_idx] = 0
                print(f"  âš ï¸  {col_name}: ëª¨ë“  ê°’ì´ ê²°ì¸¡ â†’ 0ìœ¼ë¡œ ì±„ì›€")
            else:
                # ë¶€ë¶„ì ìœ¼ë¡œ ê²°ì¸¡ì¸ ê²½ìš° í‰ê· ê°’ìœ¼ë¡œ ì±„ì›€
                col_mean = np.nanmean(col_data)
                new_data_imputed[:, col_idx] = np.where(
                    np.isnan(col_data), 
                    col_mean, 
                    col_data
                )
                print(f"  â„¹ï¸  {col_name}: {nan_count}ê°œ ê²°ì¸¡ê°’ â†’ í‰ê· ({col_mean:.2f})ìœ¼ë¡œ ì±„ì›€")
    
    # ìµœì¢… shape í™•ì¸
    print(f"\nì „ì²˜ë¦¬ ì™„ë£Œ:")
    print(f"  ìµœì¢… ë°ì´í„° shape: {new_data_imputed.shape}")
    print(f"  ìŠ¤ì¼€ì¼ëŸ¬ ì˜ˆìƒ íŠ¹ì„±: {scaler_X.n_features_in_}")
    
    # ë°ì´í„° ìŠ¤ì¼€ì¼ë§
    try:
        new_data_scaled = scaler_X.transform(new_data_imputed)
        print(f"  âœ… ìŠ¤ì¼€ì¼ë§ ì™„ë£Œ")
    except ValueError as e:
        print(f"  âŒ ìŠ¤ì¼€ì¼ë§ ì˜¤ë¥˜: {e}")
        print(f"     ì…ë ¥ ë°ì´í„° shape: {new_data_imputed.shape}")
        print(f"     ìŠ¤ì¼€ì¼ëŸ¬ ì˜ˆìƒ íŠ¹ì„±: {scaler_X.n_features_in_}")
        raise
    
    # ì‹œí€€ìŠ¤ ë°ì´í„° ìƒì„±
    X_sequences = []
    for i in range(len(new_data_scaled) - sequence_length + 1):
        X_sequences.append(new_data_scaled[i:i+sequence_length])
    
    X_sequences = np.array(X_sequences)
    
    # PyTorch í…ì„œë¡œ ë³€í™˜
    X_tensor = torch.FloatTensor(X_sequences).to(device)
    
    # LSTM ì˜ˆì¸¡
    lstm_model.eval()
    with torch.no_grad():
        lstm_predictions_scaled = lstm_model(X_tensor).cpu().numpy()
    
    lstm_predictions = scaler_y.inverse_transform(lstm_predictions_scaled)
    
    # GRU ì˜ˆì¸¡
    gru_model.eval()
    with torch.no_grad():
        gru_predictions_scaled = gru_model(X_tensor).cpu().numpy()
    
    gru_predictions = scaler_y.inverse_transform(gru_predictions_scaled)
    
    # ìŠ¤íƒœí‚¹ ëª¨ë¸ìš© íŠ¹ì„± ìƒì„±
    X_stacked = np.hstack([
        lstm_predictions.reshape(-1, 1),
        gru_predictions.reshape(-1, 1)
    ])
    
    # XGBoost ìŠ¤íƒœí‚¹ ì˜ˆì¸¡
    stacked_predictions = xgb_model.predict(X_stacked).reshape(-1, 1)
    
    return {
        'lstm_predictions': lstm_predictions.flatten(),
        'gru_predictions': gru_predictions.flatten(),
        'stacked_predictions': stacked_predictions.flatten(),
        'n_predictions': len(stacked_predictions)
    }


# === ì‚¬ìš© ì˜ˆì œ ===
if __name__ == "__main__":
    try:
        # 1. ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ
        print("\n" + "="*80)
        print("ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ ì˜ˆì œ")
        print("="*80)
        
        models = load_trained_models(model_dir='./saved_models')
        
        # 2. ìƒˆë¡œìš´ ë°ì´í„° ë¡œë“œ (ì˜ˆì œ)
        print("\nìƒˆë¡œìš´ ë°ì´í„°ë¡œ ì˜ˆì¸¡ ìˆ˜í–‰...")
        
        # ì‹¤ì œ ì‚¬ìš© ì‹œì—ëŠ” ìƒˆë¡œìš´ CSV íŒŒì¼ì´ë‚˜ ë°ì´í„°ë¥¼ ë¡œë“œ
        data_path = "./dataset/jeju_solar_utf8.csv"
        
        if not os.path.exists(data_path):
            print(f"âŒ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {data_path}")
            print("í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤...")
            
            # ë”ë¯¸ ë°ì´í„° ìƒì„±
            feature_cols = models['metadata']['feature_columns']
            n_samples = 50
            
            test_data = pd.DataFrame(
                np.random.randn(n_samples, len(feature_cols)),
                columns=feature_cols
            )
        else:
            df = pd.read_csv(data_path)
            
            # íƒ€ê²Ÿ ì»¬ëŸ¼ ì œì™¸
            target_col = 'íƒœì–‘ê´‘ ë°œì „ëŸ‰(MWh)'
            feature_cols = models['metadata']['feature_columns']
            
            # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
            missing_cols = set(feature_cols) - set(df.columns)
            if missing_cols:
                print(f"âŒ ì˜¤ë¥˜: ë‹¤ìŒ ì»¬ëŸ¼ì´ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤: {missing_cols}")
                print(f"ë°ì´í„° ì»¬ëŸ¼: {list(df.columns)}")
                raise ValueError(f"í•„ìˆ˜ íŠ¹ì„± ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing_cols}")
            
            # í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ë§ˆì§€ë§‰ 50ê°œ ë°ì´í„°ë§Œ ì‚¬ìš©
            test_data = df[feature_cols].tail(50).copy()
        
        print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„° shape: {test_data.shape}")
        print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„° ì»¬ëŸ¼: {list(test_data.columns)}")
        
        # 3. ì˜ˆì¸¡ ìˆ˜í–‰
        predictions = predict_solar_generation(
            new_data=test_data,
            models_dict=models,
            sequence_length=24
        )
        
        # 4. ê²°ê³¼ ì¶œë ¥
        print(f"\n{'='*80}")
        print("ì˜ˆì¸¡ ê²°ê³¼")
        print(f"{'='*80}")
        print(f"ì´ ì˜ˆì¸¡ ê°œìˆ˜: {predictions['n_predictions']}")
        print(f"\nLSTM ì˜ˆì¸¡ (ì²˜ìŒ 5ê°œ):")
        print(predictions['lstm_predictions'][:5])
        print(f"\nGRU ì˜ˆì¸¡ (ì²˜ìŒ 5ê°œ):")
        print(predictions['gru_predictions'][:5])
        print(f"\nìŠ¤íƒœí‚¹ ì˜ˆì¸¡ (ì²˜ìŒ 5ê°œ):")
        print(predictions['stacked_predictions'][:5])
        
        # 5. ì˜ˆì¸¡ ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ì €ì¥
        results_df = pd.DataFrame({
            'LSTM_Prediction': predictions['lstm_predictions'],
            'GRU_Prediction': predictions['gru_predictions'],
            'Stacked_Prediction': predictions['stacked_predictions']
        })
        
        output_path = './predictions_output.csv'
        results_df.to_csv(output_path, index=False, encoding='utf-8-sig')
        print(f"\nâœ… ì˜ˆì¸¡ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {output_path}")
        
        # 6. í†µê³„ ì •ë³´
        print(f"\n{'='*80}")
        print("ì˜ˆì¸¡ í†µê³„")
        print(f"{'='*80}")
        print(f"\nLSTM ì˜ˆì¸¡:")
        print(f"  í‰ê· : {predictions['lstm_predictions'].mean():.4f} MWh")
        print(f"  ìµœì†Œ: {predictions['lstm_predictions'].min():.4f} MWh")
        print(f"  ìµœëŒ€: {predictions['lstm_predictions'].max():.4f} MWh")
        print(f"  í‘œì¤€í¸ì°¨: {predictions['lstm_predictions'].std():.4f} MWh")
        
        print(f"\nGRU ì˜ˆì¸¡:")
        print(f"  í‰ê· : {predictions['gru_predictions'].mean():.4f} MWh")
        print(f"  ìµœì†Œ: {predictions['gru_predictions'].min():.4f} MWh")
        print(f"  ìµœëŒ€: {predictions['gru_predictions'].max():.4f} MWh")
        print(f"  í‘œì¤€í¸ì°¨: {predictions['gru_predictions'].std():.4f} MWh")
        
        print(f"\nìŠ¤íƒœí‚¹ ì˜ˆì¸¡:")
        print(f"  í‰ê· : {predictions['stacked_predictions'].mean():.4f} MWh")
        print(f"  ìµœì†Œ: {predictions['stacked_predictions'].min():.4f} MWh")
        print(f"  ìµœëŒ€: {predictions['stacked_predictions'].max():.4f} MWh")
        print(f"  í‘œì¤€í¸ì°¨: {predictions['stacked_predictions'].std():.4f} MWh")
        
    except FileNotFoundError as e:
        print(f"\nâŒ ì˜¤ë¥˜: {e}")
        print("ë¨¼ì € ëª¨ë¸ì„ í•™ìŠµí•˜ê³  ì €ì¥í•´ì•¼ í•©ë‹ˆë‹¤.")
        print("solar_prediction_with_save.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ëª¨ë¸ì„ í•™ìŠµí•˜ì„¸ìš”.")
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()